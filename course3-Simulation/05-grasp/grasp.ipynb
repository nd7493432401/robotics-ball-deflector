{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's edit the real world before we create the simulation\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting obj5\n",
      "deleting obj6\n",
      "deleting obj7\n",
      "deleting obj8\n",
      "deleting obj9\n",
      "deleting obj10\n",
      "deleting obj11\n",
      "deleting obj12\n",
      "deleting obj13\n",
      "deleting obj14\n",
      "deleting obj15\n",
      "deleting obj16\n",
      "deleting obj17\n",
      "deleting obj18\n",
      "deleting obj19\n",
      "deleting obj20\n",
      "deleting obj21\n",
      "deleting obj22\n",
      "deleting obj23\n",
      "deleting obj24\n",
      "deleting obj25\n",
      "deleting obj26\n",
      "deleting obj27\n",
      "deleting obj28\n",
      "deleting obj29\n"
     ]
    }
   ],
   "source": [
    "#change some colors\n",
    "RealWorld.getFrame(\"obj0\").setColor([0,1,0])\n",
    "RealWorld.getFrame(\"obj1\").setColor([1,0,0])\n",
    "RealWorld.getFrame(\"obj2\").setColor([1,1,0])\n",
    "RealWorld.getFrame(\"obj3\").setColor([1,0,1])\n",
    "RealWorld.getFrame(\"obj4\").setColor([0,1,1])\n",
    "\n",
    "#you can also change the shape & size\n",
    "RealWorld.getFrame(\"obj0\").setColor([1.,0,0])\n",
    "RealWorld.getFrame(\"obj0\").setShape(ry.ST.sphere, [.03])\n",
    "#RealWorld.getFrame(\"obj0\").setShape(ry.ST.ssBox, [.05, .05, .2, .01])\n",
    "RealWorld.getFrame(\"obj0\").setPosition([0., .2, 2.])\n",
    "\n",
    "#remove some objects\n",
    "for o in range(5,30):\n",
    "    name = \"obj%i\" % o\n",
    "    print(\"deleting\", name)\n",
    "    RealWorld.delFrame(name)\n",
    "\n",
    "V.recopyMeshes(RealWorld)\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7fb345898500>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the simulation\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're adding an \"imp\" to the simulation, which is a little process that can inject perturbations\n",
    "S.addImp(ry.ImpType.objectImpulses, ['obj0'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model world\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "#V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n",
    "\n",
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_data_to_point(pt, fxypxy):\n",
    "    pt[0] =  pt[2] * (pt[0] - fxypxy[2]) / fxypxy[0]\n",
    "    pt[1] = -pt[2] * (pt[1] - fxypxy[3]) / fxypxy[1]\n",
    "    pt[2] = -pt[2]\n",
    "    return pt\n",
    "\n",
    "def camera_to_world(pt, cameraFrame, fxfypxpy):\n",
    "    \"\"\"\n",
    "    pt = np.array([u, v, distance])\n",
    "    \"\"\"\n",
    "    cam_rot = cameraFrame.getRotationMatrix()\n",
    "    cam_trans = cameraFrame.getPosition()\n",
    "    pt = depth_data_to_point(pt, fxfypxpy) @ cam_rot.T + cam_trans\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "depth_world = []\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "        \n",
    "#         rgb = cv.cvtColor(rgb, cv.COLOR_BGR2RGB)\n",
    "        hsv = cv.cvtColor(rgb, cv.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Range for lower red\n",
    "        lower_red = np.array([0,120,70])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        mask1 = cv.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "        # Range for upper range\n",
    "        lower_red = np.array([170,120,70])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        mask2 = cv.inRange(hsv,lower_red,upper_red)\n",
    "\n",
    "        # Generating the final mask to detect red color\n",
    "        mask = mask1+mask2\n",
    "        \n",
    "        mask = cv.medianBlur(mask, 5)\n",
    "        \n",
    "#         rows = mask.shape[0]\n",
    "#         circles = cv.HoughCircles(mask, cv.HOUGH_GRADIENT, 1, rows / 8,\n",
    "#                                    param1=100, param2=30,\n",
    "#                                    minRadius=1, maxRadius=30)\n",
    "        \n",
    "#         if circles is not None:\n",
    "#             circles = np.uint16(np.around(circles))\n",
    "#             for i in circles[0, :]:\n",
    "#                 center = (i[0], i[1])\n",
    "#                 # circle center\n",
    "#                 cv.circle(rgb, center, 1, (0, 100, 100), 3)\n",
    "#                 # circle outline\n",
    "#                 radius = i[2]\n",
    "#                 cv.circle(rgb, center, radius, (255, 0, 255), 3)\n",
    "        \n",
    "        res = cv.bitwise_and(rgb,rgb,mask = mask)\n",
    "        contours, hier = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) != 0:\n",
    "#             cv.drawContours(rgb, contours, -1, (0,255,0), 3)\n",
    "#             cv.drawContours(mask, contours, -1, (0,255,0), 3)\n",
    "            for c in contours:\n",
    "#                 c = max(contours, key = cv.contourArea)\n",
    "                x,y,w,h = cv.boundingRect(c)\n",
    "                cv.rectangle(rgb,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "                x_r = x+int(w/2)\n",
    "                y_r = y+int(h/2)\n",
    "                cv.circle(rgb,(x_r, y_r), 3, (0,255,0), -1)\n",
    "\n",
    "#                 print(x_r, y_r)\n",
    "                pt = [y_r, x_r, depth[y_r, x_r]]\n",
    "                depth_world = camera_to_world(pt,cameraFrame, fxfypxpy)\n",
    "                \n",
    "                font                   = cv.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale              = 0.5\n",
    "                fontColor              = (255,255,255)\n",
    "                lineType               = 2\n",
    "                \n",
    "#                 cv.putText(rgb,str(depth[y_r, x_r]), \n",
    "#                             (x_r,y_r),\n",
    "#                             font, \n",
    "#                             fontScale,\n",
    "#                             fontColor,\n",
    "#                             lineType)\n",
    "#                 cv.putText(rgb,str(depth_world), \n",
    "#                             (x_r,y_r),\n",
    "#                             font, \n",
    "#                             fontScale,\n",
    "#                             fontColor,\n",
    "#                             lineType)\n",
    "        # Depth Points to World Coordniates\n",
    "#         depth_world = np.empty([depth.shape[0],depth.shape[1],3])\n",
    "#         for i in range(depth.shape[0]):\n",
    "#             for j in range(depth.shape[1]):\n",
    "#                 pt = [i,j,depth[i,j]]\n",
    "#                 depth_world[i,j] = camera_to_world(pt,cameraFrame, fxfypxpy)\n",
    "        \n",
    "        if len(rgb)>0: cv.imshow('OPENCV - red Mask', cv.cvtColor(res, cv.COLOR_BGR2RGB))\n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', cv.cvtColor(rgb, cv.COLOR_BGR2RGB))\n",
    "        if len(depth)>0: cv.imshow('OPENCV - depth', 0.5* depth)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = .01\n",
    "t=0\n",
    "#S.setState(Xstart, [])\n",
    "\n",
    "while True:\n",
    "    t = t+1\n",
    "    \n",
    "    if t%10 == 0:\n",
    "        S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    q = S.get_q()\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    if t<=300:\n",
    "        #q = C.getJointState()\n",
    "        [y,J] = C.evalFeature(ry.FS.oppose, [\"finger1\", \"finger2\", \"ring4\"])\n",
    "        y = y * min(.008/np.linalg.norm(y), 1.)\n",
    "        q = q - J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ y\n",
    "        \n",
    "    if t==300:\n",
    "        S.closeGripper(\"gripper\")\n",
    "        \n",
    "    if S.getGripperIsGrasping(\"gripper\"):\n",
    "        [y,J] = C.evalFeature(ry.FS.position, [\"gripper\"]);\n",
    "        q = q - J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ [0.,0.,-2e-4]\n",
    "\n",
    "    if t==900:\n",
    "        S.openGripper(\"gripper\")\n",
    "    \n",
    "    if t>1000 and S.getGripperWidth(\"gripper\")>=.02:\n",
    "        break\n",
    "\n",
    "    S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- using the viewer, you can view configurations or paths\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new frame to the MODEL configuration\n",
    "# (Perception will later have to do exactly this: add perceived objects to the model)\n",
    "obj = C.addFrame(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame parameters, associate a shape to the frame, \n",
    "obj.setPosition([.8,0,1.5])\n",
    "obj.setQuaternion([1,0,.5,0])\n",
    "obj.setShape(ry.ST.capsule, [.2,.02])\n",
    "obj.setColor([1,0,1])\n",
    "V.setConfiguration(C)\n",
    "V.recopyMeshes(C) #this is rarely necessary, only when you change meshes within C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    [y,J] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ [0.,0.,-1e-1];\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
