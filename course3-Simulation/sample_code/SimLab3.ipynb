{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../scenarios/challenge.g\")\n",
    "obj = RealWorld.addFrame(\"object\")\n",
    "pos_obj = [0,0,.9]\n",
    "obj.setPosition(pos_obj)\n",
    "obj.setQuaternion([1,0,1,0])\n",
    "d=0.1\n",
    "obj.setShape(ry.ST.ssBox, size=[d,d,d,d])\n",
    "obj.setColor([1,0,0])\n",
    "obj.setContact(1)\n",
    "#obj.setColor([0,0,1])\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "\n",
    "S.addSensor(\"camera\")\n",
    "camera = RealWorld.frame(\"camera\")\n",
    "C = ry.Config()\n",
    "C.addFile('../scenarios/pandasTable.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n",
    "\n",
    "low_threshold = np.array([30,150,50])\n",
    "upp_threshold = np.array([255,255,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6901062dbd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau = .01\n",
    "t = 0\n",
    "step = 0.05\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    t+=1\n",
    "    q = S.get_q()\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "    camera.setPosition(y)\n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.quaternion, [\"L_gripperCenter\"])\n",
    "    camera.setQuaternion(y)\n",
    "    \n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"object\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ (-y)\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)\n",
    "    \n",
    "    if t%5 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()\n",
    "        binary = cv.inRange(cv.cvtColor(rgb, cv.COLOR_BGR2HSV), low_threshold, upp_threshold) #'hue','saturation','value'.\n",
    "        #ret, binary = cv.threshold(cv.cvtColor(img, cv.COLOR_BGR2GRAY),\n",
    "        #                127, 255, cv.THRESH_BINARY)\n",
    "        contours, hier = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0:\n",
    "            (x, y), radius = cv.minEnclosingCircle(contours[0])\n",
    "            for c in contours:\n",
    "                (x1, y1), r = cv.minEnclosingCircle(c)\n",
    "                if r>radius:\n",
    "                    (x,y)=(x1, y1)\n",
    "                    radius = r\n",
    "            cv.circle(rgb, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        rv = cv.waitKey(33)\n",
    "        if rv == ord('a'):#print('left')\n",
    "            pos_obj[0] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('d'):#print('right')\n",
    "            pos_obj[0] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('w'):#print('up')\n",
    "            pos_obj[2] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('s'):#print('down')\n",
    "            pos_obj[2] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('f'):#print('front')\n",
    "            pos_obj[1] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('b'): #print('back')\n",
    "            pos_obj[1] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('q'):\n",
    "            print('Stop')\n",
    "            break\n",
    "        elif rv==ord('c'): #close\n",
    "            print('closeGripper')\n",
    "            S.closeGripper(\"L_gripper\")\n",
    "        elif rv==ord('o'): #open\n",
    "            print('openGripper')\n",
    "            S.openGripper(\"L_gripper\")\n",
    "         \n",
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visual Servoing with P controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../scenarios/challenge.g\")\n",
    "obj = RealWorld.addFrame(\"object\")\n",
    "pos_obj = [0,0,.9]\n",
    "obj.setPosition(pos_obj)\n",
    "obj.setQuaternion([1,0,1,0])\n",
    "d=0.1\n",
    "obj.setShape(ry.ST.ssBox, size=[d,d,d,d])\n",
    "obj.setColor([1,0,0])\n",
    "obj.setContact(1)\n",
    "#obj.setColor([0,0,1])\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "camera = RealWorld.frame(\"camera\")\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('../scenarios/pandasTable.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eye_in_hand = True #False for eye_to_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d726e366bdc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetQuaternion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau = .01\n",
    "t = 0\n",
    "step = 0.05\n",
    "low_threshold = np.array([30,150,50])\n",
    "upp_threshold = np.array([255,255,180])\n",
    "camera.setQuaternion([1,1,0,0])\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "    t+=1\n",
    "    pose = np.zeros(7)\n",
    "    [y_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "    pose[:3] = y_pos\n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.quaternion, [\"L_gripperCenter\"])\n",
    "    pose[3:] = y\n",
    "    if eye_in_hand:\n",
    "        camera.setPosition(y_pos)\n",
    "        #camera.setQuaternion(y)\n",
    "    if t%5 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()\n",
    "        binary = cv.inRange(cv.cvtColor(rgb, cv.COLOR_BGR2HSV), low_threshold, upp_threshold) #'hue','saturation','value'.\n",
    "        contours, hier = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0:\n",
    "            (x, y), radius = cv.minEnclosingCircle(contours[0])\n",
    "            for c in contours:\n",
    "                (x1, y1), r = cv.minEnclosingCircle(c)\n",
    "                if r>radius:\n",
    "                    (x,y)=(x1, y1)\n",
    "                    radius = r\n",
    "            cv.circle(rgb, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "            f = 0.895\n",
    "            f = f * 360.                                       # Focal length in pixel\n",
    "            diameter_real = d * 360                    # 0.1     in pixels \n",
    "            k=0.02 #gains\n",
    "            \n",
    "            Z = (f*(diameter_real/2.0))/radius      #circle depth            \n",
    "            xy_target = np.array([x,Z,y]) #my corners\n",
    "            xy_desired = np.array([640/2, 200.0, 360/2]) #center of the image\n",
    "            err = xy_desired - xy_target            #error in camera frame\n",
    "            \n",
    "            [ee_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "\n",
    "            vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(ee_pos.shape[0])) @ [-k*err[0], -k*err[1], k*err[2]]\n",
    "            S.step(vel, tau, ry.ControlMode.velocity)\n",
    "            #Visual servoing here ----------------------------------------------\n",
    "\n",
    "        if len(rgb)>0: \n",
    "            cv.imshow('OPENCV - rgb', rgb)        \n",
    "        rv = cv.waitKey(33)\n",
    "        if rv == ord('a'):#print('left')\n",
    "            pos_obj[0] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('d'):#print('right')\n",
    "            pos_obj[0] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('w'):#print('up')\n",
    "            pos_obj[2] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('s'):#print('down')\n",
    "            pos_obj[2] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('f'):#print('front')\n",
    "            pos_obj[1] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('b'): #print('back')\n",
    "            pos_obj[1] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('q'):\n",
    "            print('Stop')\n",
    "            break\n",
    "\n",
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visual servoing with Image Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../scenarios/challenge.g\")\n",
    "obj = RealWorld.addFrame(\"object\")\n",
    "pos_obj = [0,0,.9]\n",
    "obj.setPosition(pos_obj)\n",
    "obj.setQuaternion([1,0,1,0])\n",
    "d=0.1\n",
    "obj.setShape(ry.ST.ssBox, size=[d,d,d,d])\n",
    "obj.setColor([1,0,0])\n",
    "obj.setContact(1)\n",
    "#obj.setColor([0,0,1])\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "camera = RealWorld.frame(\"camera\")\n",
    "C = ry.Config()\n",
    "C.addFile('../scenarios/pandasTable.g')\n",
    "\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eye_in_hand = True #False for eye_to_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96709e31a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENCV - rgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#print('left')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mpos_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau = .01\n",
    "t = 0\n",
    "step = 0.05\n",
    "low_threshold = np.array([30,150,50])\n",
    "upp_threshold = np.array([255,255,180])\n",
    "camera.setQuaternion([1,1,0,0])\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "    t+=1\n",
    "    pose = np.zeros(7)\n",
    "    [y_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "    pose[:3] = y_pos\n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.quaternion, [\"L_gripperCenter\"])\n",
    "    pose[3:] = y\n",
    "    if eye_in_hand:\n",
    "        camera.setPosition(y_pos)\n",
    "        #camera.setQuaternion(y)\n",
    "        \n",
    "    if t%5 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()\n",
    "        binary = cv.inRange(cv.cvtColor(rgb, cv.COLOR_BGR2HSV), low_threshold, upp_threshold) #'hue','saturation','value'.\n",
    "        contours, hier = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0:\n",
    "            (x, y), radius = cv.minEnclosingCircle(contours[0])\n",
    "            for c in contours:\n",
    "                (x1, y1), r = cv.minEnclosingCircle(c)\n",
    "                if r>radius:\n",
    "                    (x,y)=(x1, y1)\n",
    "                    radius = r\n",
    "            cv.circle(rgb, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "            f = 0.895\n",
    "            f = f * 360.                                       # Focal length in pixel\n",
    "            diameter_real = d * 360                    # 0.1     in pixels \n",
    "            k=0.03 #gains\n",
    "            \n",
    "            Z = (f*(diameter_real/2.0))/radius      #circle depth            \n",
    "            xy_target = np.array([x,y,radius]) #my corners\n",
    "            xy_desired = np.array([640/2, 360/2, 45.0]) #center of the image\n",
    "            err = xy_target - xy_desired             #error in camera frame\n",
    "\n",
    "            Jv = getImageJacobianCFToFF(xy_target[0], xy_target[1], Z, f, diameter_real)\n",
    "            vel_J = np.dot(np.linalg.inv(Jv),err)\n",
    "            [ee_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "            \n",
    "            vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(ee_pos.shape[0])) @ [-k*vel_J[0], k*vel_J[2], k*vel_J[1]]\n",
    "            S.step(vel, tau, ry.ControlMode.velocity)\n",
    "            #Visual servoing here ----------------------------------------------\n",
    "        \n",
    "        if len(rgb)>0: \n",
    "            cv.imshow('OPENCV - rgb', rgb)        \n",
    "        rv = cv.waitKey(33)\n",
    "        if rv == ord('a'):#print('left')\n",
    "            pos_obj[0] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('d'):#print('right')\n",
    "            pos_obj[0] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('w'):#print('up')\n",
    "            pos_obj[2] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('s'):#print('down')\n",
    "            pos_obj[2] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('f'):#print('front')\n",
    "            pos_obj[1] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('b'): #print('back')\n",
    "            pos_obj[1] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('q'):\n",
    "            print('Stop')\n",
    "            break\n",
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getImageJacobianCFToFF(u, v, z, f, diameter):\n",
    "    Jv = np.zeros((3,3))\n",
    "    \n",
    "    Jv[0][0] = -f/z\n",
    "    Jv[0][1] = 0\n",
    "    Jv[0][2] = u/z\n",
    "    \n",
    "    Jv[1][0] = 0\n",
    "    Jv[1][1] = -f/z\n",
    "    Jv[1][2] = v/z\n",
    "\n",
    "    Jv[2][0] = 0\n",
    "    Jv[2][1] = 0\n",
    "    Jv[2][2] = -(diameter*f)/(z*z)\n",
    "\n",
    "    return Jv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visual servoing with red object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../scenarios/challenge.g\")\n",
    "obj = RealWorld.addFrame(\"object\")\n",
    "pos_obj = [0,0,.9]\n",
    "obj.setPosition(pos_obj)\n",
    "obj.setQuaternion([1,0,1,0])\n",
    "d=0.1\n",
    "obj.setShape(ry.ST.ssBox, size=[d,d,d,d])\n",
    "obj.setColor([1,0,0])\n",
    "obj.setContact(1)\n",
    "#obj.setColor([0,0,1])\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "camera = RealWorld.frame(\"camera\")\n",
    "C = ry.Config()\n",
    "C.addFile('../scenarios/pandasTable.g')\n",
    "\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eye_in_hand = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-76a2805364f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mblurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "import imutils\n",
    "\n",
    "tau = .01\n",
    "t = 0\n",
    "step = 0.05\n",
    "camera.setQuaternion([1,1,0,0])\n",
    "low_threshold = np.array([30,150,50])\n",
    "upp_threshold = np.array([255,255,180])\n",
    "cap = cv.VideoCapture(0)\n",
    "time.sleep(1.0)\n",
    "pts = deque(maxlen=10)\n",
    "vs = cap\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "    t+=1\n",
    "    pose = np.zeros(7)\n",
    "    [y_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "    pose[:3] = y_pos\n",
    "    [y,J] = RealWorld.evalFeature(ry.FS.quaternion, [\"L_gripperCenter\"])\n",
    "    pose[3:] = y\n",
    "    if eye_in_hand:\n",
    "        camera.setPosition(y_pos)\n",
    "        #camera.setQuaternion(y)\n",
    "    if t%5 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()\n",
    "        \n",
    "        \n",
    "        ret, frame = vs.read()\n",
    "        if frame is not None:\n",
    "            blurred = cv.GaussianBlur(frame, (11, 11), 0)\n",
    "            hsv = cv.cvtColor(blurred, cv.COLOR_BGR2HSV)\n",
    "\n",
    "            mask = cv.inRange(hsv, low_threshold, upp_threshold)\n",
    "            mask = cv.erode(mask, None, iterations=2) #Erosion\n",
    "            mask = cv.dilate(mask, None, iterations=2)\n",
    "    \n",
    "            \n",
    "            cnts = cv.findContours(mask.copy(), cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            center = None\n",
    "            \n",
    "            if len(cnts) > 0:\n",
    "                c = max(cnts, key=cv.contourArea)\n",
    "                ((x, y), radius) = cv.minEnclosingCircle(c)\n",
    "                M = cv.moments(c)\n",
    "                center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "                if radius > 10:\n",
    "                    cv.circle(frame, (int(x), int(y)), int(radius),\n",
    "                        (0, 255, 255), 2)\n",
    "                    cv.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "                    (x1, y1) = x, y\n",
    "\n",
    "            pts.appendleft(center)\n",
    "\n",
    "            for i in range(1, len(pts)):\n",
    "                if pts[i - 1] is None or pts[i] is None:\n",
    "                    continue\n",
    "\n",
    "                thickness = int(np.sqrt(6 / float(i + 1)) * 2.5)\n",
    "                if thickness > 0:\n",
    "                    cv.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)            \n",
    "\n",
    "            f = 0.895\n",
    "            f = f * 360.                                       # Focal length in pixel\n",
    "            diameter_real = d * 360                    # 0.1     in pixels \n",
    "            k=0.02 #gains\n",
    "\n",
    "            Z = (f*(diameter_real/2.0))/radius      #circle depth            \n",
    "            xy_target = np.array([x1,Z,y1]) #my corners\n",
    "            xy_desired = np.array([640/2, 200.0, 360/2]) #center of the image\n",
    "            err = xy_desired - xy_target            #error in camera frame\n",
    "            [ee_pos,J] = RealWorld.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "\n",
    "            vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(ee_pos.shape[0])) @ [-k*err[0], -k*err[1], k*err[2]]\n",
    "            S.step(vel, tau, ry.ControlMode.velocity)\n",
    "            #Visual servoing here ----------------------------------------------\n",
    "\n",
    "        if len(rgb)>0: \n",
    "            cv.imshow('OPENCV - rgb', rgb) \n",
    "            cv.imshow('frame',frame)\n",
    "        rv = cv.waitKey(33)\n",
    "        if rv == ord('a'):#print('left')\n",
    "            pos_obj[0] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('d'):#print('right')\n",
    "            pos_obj[0] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('w'):#print('up')\n",
    "            pos_obj[2] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('s'):#print('down')\n",
    "            pos_obj[2] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('f'):#print('front')\n",
    "            pos_obj[1] += step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('b'): #print('back')\n",
    "            pos_obj[1] -= step\n",
    "            obj.setPosition(pos_obj)\n",
    "        elif rv==ord('q'):\n",
    "            print('Stop')\n",
    "            break\n",
    "\n",
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "C = 0\n",
    "RealWorld = 0\n",
    "S = 0\n",
    "V=0\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4a70be8e9160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "low_threshold = np.array([30,150,50])\n",
    "upp_threshold = np.array([255,255,180])\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if img is None:\n",
    "        #break\n",
    "        print('Frame is none')\n",
    "        continue\n",
    "   \n",
    "    binary = cv.inRange(cv.cvtColor(img, cv.COLOR_BGR2HSV), low_threshold, upp_threshold) #'hue','saturation','value'.\n",
    "    #ret, binary = cv.threshold(cv.cvtColor(img, cv.COLOR_BGR2GRAY),\n",
    "     #               127, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    contours, hier = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    #-----------------------------------------------------------------------\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        (x, y), radius = cv.minEnclosingCircle(c)\n",
    "        center = (int(x), int(y))\n",
    "        radius = int(radius)\n",
    "        img = cv.circle(img, center, radius, (255, 0, 0), 2)\n",
    "\n",
    "    cv.drawContours(img, contours, -1, (255, 255, 0), 1)\n",
    "    cv.imshow(\"img withcontours\", img)\n",
    "    cv.imshow('binary',binary)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "ret, first = cap.read()\n",
    "\n",
    "first_gray = cv.cvtColor(first, cv.COLOR_BGR2GRAY)\n",
    "first_gray = cv.GaussianBlur(first_gray, (21, 21), 0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    gray = cv.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    difference = cv.absdiff(gray, first_gray)\n",
    "\n",
    "    thresh = cv.threshold(difference, 25, 255, cv.THRESH_BINARY)[1]\n",
    "    thresh = cv.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    contours, hier = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) != 0:\n",
    "        cv.drawContours(frame, contours, -1, 255, 3)\n",
    "        c = max(contours, key = cv.contourArea)\n",
    "        x,y,w,h = cv.boundingRect(c)\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow(\"thresh\", thresh)\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
